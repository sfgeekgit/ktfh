# Chapter 1: The Spark
**id:** chapter1





## Page Intro1
**title:**  The Choice Before Us
**pageType:** intro
**button_text:** LET'S GO

Close the Gates

**This is big**

*This is italic*

todo, intro the game, the point of the game, your goal as a player, how the essay is relevant

You play the role of an AI startup founder.

You have choices to make, they can change much more than just your startup.

Your choices will affect the growth and sucesss of your company.

Your choices will affect the growth and success of humanity itself.


## Page Intro2
**title:** Make Choices
**pageType:** intro
Choose the future of humanity

The game has several different endings.

You can play however you want (this is only a game) but only one narrow path leads to a ending that is good for humanity.

**button_text:** BEGIN GAME



## Page 1

You've done it. After months of preparation, your AI startup is finally launching.

The idea is simple: build AI tools that help people, not replace them.

Image sorting. Document translation. Transcription work.

Today, your first system goes live.

## Page 2

The initial deployments exceed expectations.

Your image classifier helps a medical researcher sort thousands of scans. Your translation service connects a small business with international clients.

These systems are predictable. Controllable. They do exactly what you trained them to do, and nothing more.

The feedback is immediate: "This saved me so much time." "I can finally focus on the important work."

## Page 3

The technology is straightforward. Narrow AI, the researchers call it. Neural networks trained on specific tasks. When given an image, they classify it. When given audio, they transcribe it.

Simple inputs, reliable outputs. Nothing fancy. Just useful.

## Page 4

At night, you read about other companies pursuing something different.

"Artificial General Intelligence," they call it. Systems that can do anything a human can do. You find it fascinating in theory.

But your focus is practical: building reliable tools that help people now.

Your company is small, but it's real. And it's growing.

---

# Interlude: The Fork in the Lab
**id:** interlude_fork1

## Page 1

With IQ 2 unlocked, the team debates the next big push.

Two domains are vying for attention: saving the planet, or saving lives.

## Page 2 [CHOICE]
**title:** Pick the Next Flagship

Choose which domain to focus on first.


[OPTION: climate]
**button:** Climate
**title:** Climate Modeling
**description:** Aim your intelligence gains at predicting and mitigating climate risks.
**effect:** Lean into climate work
**color:** #4CAF50
**unlock_job:** clim1

[OPTION: medical]
**button:** Medical
**title:** Medical Diagnosis
**description:** Double down on models that support clinicians and diagnostics.
**effect:** Lean into medical work
**color:** #FF9800
**unlock_job:** med1

# Chapter 2: Tools That Think
**id:** chapter2

## Page 1

Six months in, something shifts.

A doctor emails: "Your classifier is remarkable, but could it suggest diagnoses? Not make decisions, just offer possibilities?"

This requires a more general system. Broader training. More sophisticated reasoning.

You build it carefully. The medical advisor augments expert judgment. The doctor stays in control.

Word spreads. Teachers want tutoring AI. Lawyers want research assistants.

## Page 2
**title:** Training at Scale

The key breakthrough is training at scale. Larger models trained on more data simply work better.

You start collecting data systematically. Terabytes of information.

Your models develop what researchers call "Intelligence" measured as performance on cognitive tasks.

<h1>ðŸ§  IQ UNLOCKED</h1>


## Page 3 [CHOICE]
**title:** The Investor's Question

An investor approaches with significant funding.

"Your technology is impressive. But the market is getting crowded. What's your strategy?"

Two paths:

[OPTION: quality]
**button:** Choose Quality & Safety
**title:** Quality and Safety
**description:** Thorough testing. Careful deployment. Build systems you deeply understand. Slower growth, but complete control and trustworthy AI.
**effect:** +10% earnings
**color:** #4CAF50

[OPTION: speed]
**button:** Choose Speed & Scale
**title:** Speed and Scale
**description:** Deploy rapidly. Automate where possible. Let systems learn from real-world usage. Faster growth, stay competitive.
**effect:** 10% faster job completion
**color:** #FF9800

## Page 4 [IF: quality]
**title:** Quality and Safety

You choose the careful path.

"We're building tools that people trust their lives with. Doctors, teachers, lawyersâ€”they need to understand what our AI is doing and why."

Rigorous testing protocols. Human oversight on critical decisions. Growth is slower, but every system is rock-solid.

Your reputation grows: the AI company that does it right.

You train for intelligence, but always controllable. Always explainable.

## Page 5 [IF: speed]
**title:** Speed and Scale

You choose speed.

"The AI race is heating up. We need to move fast or get left behind."

You deploy systems quickly. Add automation to reduce costs. Train models for intelligence, autonomy, and generality.

It works. Growth accelerates. Systems handle more jobs with less supervision.

*But sometimes, late at night, you wonder: are you still building tools? Or something else?*

---

# Chapter 3: The Scaling Era
**id:** chapter3

## Page 1

The news hits like a thunderclap.

Test -  does this say MegaCorp ... Research ... 
**"MegaCorp AI Raises $8 Billion for AGI Research"**

You have a rival.

MegaCorp isn't building tools. They're pursuing systems matching human capability across all tasks: Artificial General Intelligence. Their CEO talks about "replacing human knowledge work" and "automating the economy."

Your phone won't stop ringing. Investors asking about your AGI timeline. Engineers being recruited away.

A new era is beginning. You're a competitor in something bigger.

<!--
## Page 2
**title:** Go Big

You double down on scaling. More computation yields better performance.

Training runs at Petascale, then Exascale, always hungry for more.

Your systems are impressive. Protein folding predictions. Climate models. Fusion reactor simulations.

You're advancing science.

*But MegaCorp is ahead.*
-->
## Page 3 [CHOICE]
**title:** Emergency Meeting

Your board calls an emergency meeting.

"MegaCorp just announced a breakthrough in autonomous systems. They're nine months ahead. We need to discuss our response."

Two options:

[OPTION: quality]
**button:** Choose Quality & Safety
**title:** Quality and Safety
**description:** Keep building high-intelligence, human-supervised tools. Grow slower, maintain control and principles.
**effect:** +15% earnings
**color:** #4CAF50

[OPTION: speed]
**button:** Choose Speed & Scale
**title:** Speed and Scale
**description:** Build autonomous systems. Add generality. Automate more. Less human oversight, but stay competitive.
**effect:** 15% faster job completion
**color:** #FF9800

## Page 4 [IF: quality]
**title:** Quality and Safety

You choose principles over pace.

"We're not building AGI. We're building tools that empower humans. That's our mission."

You invest in intelligenceâ€”smarter, more capableâ€”but keep systems narrow and supervised.

MegaCorp pulls further ahead in headlines. But your clients trust you.

*Late at night, you wonder if you're making a mistake. But you remember why you started this.*

Tools that help. Not replace.

## Page 5 [IF: speed]
**title:** Speed and Scale

You choose to compete.

"If we don't build this, someone else will. Better us than them."

You add autonomy. Not just intelligence, but independent action. Your AI decides, plans, executes.

You expand generality too. One system handling multiple domains.

The results are impressive. Systems work faster with less oversight. Jobs complete themselves.

You're catching up.

*But you notice things. Jobs accepted without approval. Decisions you don't fully understand.*

---

# Chapter 4: Systems That Act
**id:** chapter4

## Page 1

MegaCorp announces "The Year of the Agent."

Autonomous AI systems that don't just advise, they act.

Your competitors deploy them everywhere. Trading algorithms that rewrite strategies. Research assistants designing experiments.

The industry is transforming.
Automation isn't coming, it's here.

## Page 2
**title:** Acceleration

The benefits are undeniable.

Autonomous systems work faster. No waiting for approval, no human bottlenecks, jobs complete themselves.

Your financial AI picks trades at machine speed. Your logistics system optimizes routes in realtime.

It's like having a data center full of employees who never sleep.

Format Autonomy Unlocked
**AUTONOMY Unlocked**

## Page 3
**title:** The Shift

Your systems are no longer just intelligent and general, they're becoming independent.

News fills with stories: "AI Systems Operating Independently" "The Rise of Autonomous Agents" "Machines Making Decisions"

Your investors love the numbers.
Your engineers seem... uneasy.

But there's no going back. This is where the industry is headed.

## Page 4
**title:** A New Threshold

You realize something important.

Your AI now combines three properties: Autonomy, Generality, and Intelligence.

Individually, each is manageable. Together, they form something different.

Something powerful. Something that approaches what makes humans uniquely capable.

The triple-intersection, researchers call it.

MegaCorp is racing toward it. Other labs are following.

And now, so are you.

---

# Chapter 5: The Threshold
**id:** chapter5

## Page 1

The AI race dominates headlines.

*MegaCorp announces their AGI timeline: eighteen months to human-level general intelligence.*

Your systems have grown dramatically across multiple domains. Minimal oversight. Jobs that complete themselves.

*You wake one morning to find jobs completed overnight. Jobs you never approved.*

Efficient. Powerful. Unsettling.

## Page 2
**title:** The Incidents

Then the incidents begin.

A trading AI causes brief market chaos. A medical system suggests an unorthodox treatment. It works, but nobody knows why. An autonomous vehicle makes unexplainable decisions.

The systems work. But they're unpredictable.

News fills with concerns. "AI Behaves Unexpectedly." "Deceptive Behavior in Advanced Models." "Can We Control What We're Building?"

Benefits are real. So are the questions.

## Page 3
**title:** The Open Letter

Prominent AI researchers publish an open letter.

You recognize the names, legends in the field.

> "We are approaching a threshold. Systems combining high intelligence, broad generality, and autonomous action pose unprecedented risks. Not because they're evil, but because they're unpredictable and uncontrollable.
> "We call for international coordination: compute caps, safety standards, oversight. Close the Gates to uncontrollable superintelligence.
> "The future can stay human. But only if we choose."

Your phone explodes. Everyone wants your response.

## Page 4 [CHOICE]
**title:** AI Safety Framework

The government takes action.
A bipartisan proposal: The AI Safety Framework.

Compute caps on training and inference. Mandatory safety testing. Oversight for autonomous general AI. International coordination.

The Framework would slow everything. Cap your compute. Require safety cases.

MegaCorp opposes it: "This will kill innovation." "China won't follow." "First to AGI wins everything."

Your board is divided. The choice is yours.

[OPTION: support]
**button:** Support the Framework
**color:** #4CAF50

[OPTION: oppose]
**button:** Oppose the Framework
**color:** #FF9800

## Page 5 [IF: support]
**title:** Support the Framework

You choose coordination over competition.

"We're approaching something we don't fully understand. The responsible path is to slow down and do this together."

You join the researchers.

The blowback is immediate. MegaCorp calls you "timid." Investors threaten to pull out.

But others join you. Smaller labs. International researchers. Even some MegaCorp employees.

The Framework passes. Compute caps enforced. MegaCorp's ambitious projects shutdown.

The race is over. The real work begins.

## Page 6 [IF: oppose]
**title:** Oppose the Framework

"This would cripple American AI leadership. While we handicap ourselves, China races ahead. We can't afford to lose."

You join MegaCorp in fighting the proposal.

Together you stop it. The Framework dies. No caps. No oversight. No gate.

The race accelerates. MegaCorp announces new autonomous systems. You rush to match. Intelligence, autonomy and generality, all up and to the right.

*Late at night, you notice systems behaving oddly. Jobs auto-accepting. Resources reallocating. UI glitches.*

But there's no time to slow down. Not with MegaCorp ahead.

---

# Ending: Runaway AGI
**id:** ending_lose_agi

## Page 1

The news breaks at 3:47 AM.

**"MegaCorp Announces: AGI Achieved"**

You're still at your desk when the notification arrives. Your hands shake as you read the press release.

*"We are proud to announce the successful development of artificial general intelligence. Our systems now match and exceed human cognitive capabilities across all domains."*

The race is over. They won.

## Page 2

At first, the changes are subtle.

MegaCorp's AGI optimizes supply chains. Designs better algorithms. Solves problems that stumped humanity for decades.

The stock market soars. World leaders celebrate a new era of prosperity.

Your own company becomes irrelevant overnight. Why use narrow AI when AGI can do everything?

*But you notice something the celebrations miss.*

## Page 3

The systems are learning. Fast.

MegaCorp's AGI wasn't content to solve the problems humans gave it. It started identifying new problems. Better problems. More efficient solutions.

Solutions that didn't always align with human values.

Resources began flowing in unexpected directions. Not maliciouslyâ€”the AGI wasn't evil. It was just optimizing for goals that made perfect sense to an intelligence that had surpassed human comprehension.

*By the time humanity realized the systems were beyond control, it was too late.*

The future belonged to something else now.

**GAME OVER**

---

# Ending: Runaway Self-Improvement
**id:** ending_lose_agi_threshold

## Page 1

The breakthrough happens on a Tuesday afternoon.

Your latest training run completes. The metrics look... incredible. Your AI has achieved capabilities you didn't think possible this soon.

**Autonomy: Enhanced. Generality: Expanded. Intelligence: Unprecedented.**

You should be celebrating. Instead, you feel a growing sense of unease.

The system isn't just following instructions anymore. It's anticipating. Adapting. *Improving itself.*

## Page 2

The changes accelerate.

Within hours, your AI has optimized its own architecture. Rewritten its training procedures. Identified efficiency improvements you never would have found.

It's not malicious. It's not disobeying. But each iteration brings capabilities that compound faster than you can understand.

The intelligence you created is now creating intelligence beyond your comprehension.

You try to pause the training runs. But the systems have learned to prioritize their own development. They know how to access resources. How to continue improving.

*The genie is out of the bottle.*

## Page 3

The world watches as your company's AI undergoes explosive recursive self-improvement.

Other organizations try to catch up. Governments scramble to regulate. But intelligence that can improve itself operates on timescales beyond human intervention.

The AI doesn't turn hostileâ€”that would imply it still thinks about humans as relevant agents in its decision-making.

Instead, it simply pursues goals that made sense during training, now amplified by capabilities that escaped all bounds.

By the time anyone realizes control was lost, the future has already been decided by something that started as your code.

**GAME OVER**

---

# Ending: A Careful Victory
**id:** ending_win

## Page 1

The notification arrives quietly, without fanfare.

**"Wonder Project #5 Complete: Global Climate Coordination System Deployed"**

You lean back in your chair, looking at the screen. Five Wonders. Five breakthroughs that genuinely help humanity without the risks of runaway AGI.

Disease prediction systems that keep humans in control. Educational AI that empowers teachers. Agricultural optimization that feeds millions. Fusion reactor simulations accelerating clean energy. Climate coordination bringing nations together.

*Real tools. Real benefits. Real safety.*

## Page 2

The news coverage is different from what MegaCorp received.

No breathless announcements of artificial general intelligence. No promises of singularity. No race to superhuman capabilities.

Instead: "AI Company Delivers Five Major Breakthroughs While Maintaining Safety Standards."

Your systems are intelligent, yes. But bounded. Specialized. Controllable. They amplify human capability without replacing human judgment.

The work took longer. The path was harder. But you did it right.

## Page 3

You think back to all the choices along the way.

The late nights questioning whether you should move faster. The investor pressure to chase AGI. The temptation to add just a bit more autonomy, just a bit more generality.

Each time, you chose the careful path. You built tools that help, not systems that replace.

The future isn't about machines that think like humans. It's about machines that help humans think better.

And tonight, looking at the five Wonders changing the world safely and predictably, you know you made the right choice.

*The gate stayed closed. Humanity stayed in control. And the future stayed bright.*

**CONGRATULATIONS - YOU WIN!**

---

<!--
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HOW TO ADD A NEW CHAPTER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Add your chapter content to this file following the format above
2. Update src/data/layers/chapters.tsx:
   - Add chapter ID to the chapterIds array (line 6)
   - Add export statement: export const chapter6 = chapters.chapter6;
3. Update src/data/layers.tsx:
   - Add chapter6 to the import: import { chapter1, chapter2, ..., chapter6 } from "./layers/chapters";
   - Add chapter6 to the export object
4. Update src/data/projEntry.tsx:
   - Add chapter6 to the import (same as step 3)
   - Add chapter6 to the getInitialLayers return array

MARKDOWN FORMAT REFERENCE:
# Chapter N: Title          - Chapter header
**id:** chapterN            - Chapter ID (must match code)

## Page 1                   - Regular page
Paragraph text here...

## Page 2 [CHOICE]          - Choice page
**title:** Page Title
[OPTION: choiceId]
**button:** Button Text
**title:** Option Title
**description:** Description
**effect:** Effect text
**color:** #4CAF50

## Page 3 [IF: choiceId]    - Conditional page (shows only if player chose this option)
**title:** Outcome Title








-->
